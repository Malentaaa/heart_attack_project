{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import shap\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import shapiro\n",
    "from pandas.api.types import is_integer_dtype\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import  (\n",
    "    fbeta_score, f1_score, precision_score, recall_score, roc_auc_score,\n",
    "    confusion_matrix, make_scorer, average_precision_score\n",
    ")\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import shap\n",
    "from typing import Optional, List\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.25\n",
    "TARGET_COL = \"heart_attack_risk_binary\"\n",
    "K_BEST       = 15                    \n",
    "SCORE_FUNC   = f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "heart_train = pd.read_csv('C:/Users/malen/OneDrive/Desktop/data_since/мастерская 1/data/raw/heart_train.csv', index_col='id')\n",
    "heart_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "heart_test = pd.read_csv('C:/Users/malen/OneDrive/Desktop/data_since/мастерская 1/data/raw/heart_test.csv', index_col='id')\n",
    "heart_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "heart_train = heart_train.drop('Unnamed: 0', axis=1)\n",
    "heart_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "heart_test = heart_test.drop('Unnamed: 0', axis=1)\n",
    "heart_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def to_snake_case(name):\n",
    "    name = name.strip()\n",
    "    name = re.sub(r'[\\s\\-]+', '_', name)               # пробелы и дефисы → _\n",
    "    name = re.sub(r'([a-z0-9])([A-Z])', r'\\1_\\2', name) # camelCase → camel_case\n",
    "    name = re.sub(r'[^\\w_]', '', name)                  # убрать лишние символы\n",
    "    return name.lower()\n",
    "\n",
    "heart_train.columns = [to_snake_case(c) for c in heart_train.columns]\n",
    "heart_test.columns = [to_snake_case(c) for c in heart_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_gender(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    male/female, '1'/'0', '1.0'/'0.0' -> {1.0, 0.0}, NaN сохраняем\n",
    "    \"\"\"\n",
    "    s = series.astype(str).str.strip().str.lower()\n",
    "    s = (s.replace({\"male\":\"1\",\"female\":\"0\"})\n",
    "           .str.replace(\".0\",\"\", regex=False)\n",
    "           .replace({\"nan\": np.nan}))\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "    \n",
    "if \"gender\" in heart_train.columns:\n",
    "    heart_train[\"gender\"] = normalize_gender(heart_train[\"gender\"])\n",
    "if \"gender\" in heart_test.columns:\n",
    "    heart_test[\"gender\"] = normalize_gender(heart_test[\"gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# === Удаляем признаки-утечки прямо из DataFrame: CK-MB и Troponin ==============\n",
    "heart_train = heart_train.drop(columns=[\"ck_mb\", \"troponin\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---------------- кастомные трансформеры ---------------- #\n",
    "class GroupMedianImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        X_df = pd.DataFrame(X)\n",
    "        self.medians_ = X_df.median(numeric_only=False)\n",
    "        self.feature_names_in_ = X_df.columns.to_list()\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return pd.DataFrame(X, columns=self.feature_names_in_).fillna(self.medians_).values\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return np.array(self.feature_names_in_ if input_features is None else input_features)\n",
    "\n",
    "class ModeImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        X_df = pd.DataFrame(X)\n",
    "        self.modes_ = X_df.mode(dropna=True).iloc[0]\n",
    "        self.feature_names_in_ = X_df.columns.to_list()\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return pd.DataFrame(X, columns=self.feature_names_in_).fillna(self.modes_).values\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return np.array(self.feature_names_in_ if input_features is None else input_features)\n",
    "\n",
    "class BinaryCleaner(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_names_in_ = pd.DataFrame(X).columns.to_list()\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        arr = np.asarray(X, dtype=float)\n",
    "        arr = np.rint(arr)\n",
    "        arr = np.clip(arr, 0, 1)\n",
    "        return arr.astype(np.int8)\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return np.array(self.feature_names_in_ if input_features is None else input_features)\n",
    "\n",
    "class MissingIndicatorSimple(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_names_in_ = pd.DataFrame(X).columns.to_list()\n",
    "        self.out_names_ = [f\"{c}__was_missing\" for c in self.feature_names_in_]\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_df = pd.DataFrame(X, columns=self.feature_names_in_)\n",
    "        return X_df.isna().astype(np.int8).values\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return np.array(self.out_names_)\n",
    "\n",
    "# ---------------- списки признаков под наш проект ---------------- #\n",
    "# NB: ck_mb и troponin уже удалены из самого df; формируем фичи без них\n",
    "all_cols = [c for c in heart_train.columns if c != TARGET_COL]\n",
    "\n",
    "binary_features = [\n",
    "    \"diabetes\",\"family_history\",\"smoking\",\"obesity\",\"alcohol_consumption\",\n",
    "    \"previous_heart_problems\",\"medication_use\",\"gender\"\n",
    "]\n",
    "binary_features = [c for c in binary_features if c in all_cols]\n",
    "\n",
    "ordinal_features = [\n",
    "    \"diet\", \"stress_level\", \"physical_activity_days_per_week\"\n",
    "]\n",
    "ordinal_features = [c for c in ordinal_features if c in all_cols]\n",
    "\n",
    "numeric_features = [c for c in all_cols if c not in binary_features + ordinal_features]\n",
    "\n",
    "# ---------------- пайплайны по типам ---------------- #\n",
    "num_pipe = Pipeline([\n",
    "    (\"imp\", GroupMedianImputer()),\n",
    "    # (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "ord_pipe = Pipeline([\n",
    "    (\"imp\", GroupMedianImputer())\n",
    "])\n",
    "\n",
    "bin_pipe = Pipeline([\n",
    "    (\"imp\", ModeImputer()),\n",
    "    (\"bin\", BinaryCleaner())\n",
    "])\n",
    "\n",
    "# ---------------- единый препроцессор ---------------- #\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipe, numeric_features),\n",
    "        (\"ord\", ord_pipe, ordinal_features),\n",
    "        (\"bin\", bin_pipe, binary_features),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "LEAK_COLS = [c for c in [\"ck_mb\", \"troponin\"] if c in heart_train.columns]\n",
    "# ====== данные ======\n",
    "use_cols = [c for c in heart_train.columns if c not in LEAK_COLS + [TARGET_COL]]\n",
    "X = heart_train[use_cols].copy()\n",
    "y = heart_train[TARGET_COL].astype(int).copy()\n",
    "\n",
    "# ====== пайплайн: препроцессор -> SelectKBest -> RandomForest (твои лучшие параметры) ======\n",
    "rf_best = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    min_samples_split=2,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"prep\",   preprocessor),                  # твой ColumnTransformer\n",
    "    (\"select\", SelectKBest(score_func=SCORE_FUNC, k=K_BEST)),\n",
    "    (\"clf\",    rf_best),\n",
    "])\n",
    "\n",
    "# ====== hold-out валидация ======\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# обучаем на train\n",
    "pipe.fit(X_tr, y_tr)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
